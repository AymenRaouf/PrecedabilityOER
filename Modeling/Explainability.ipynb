{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000 NaN values in chapters.\n",
      "0000 Nan values in concepts.\n",
      "0000 Nan values in classes.\n",
      "0000 Nan values in episdes precedences.\n",
      "0000 Nan values in series precedences.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "main_publisher = 'OYC'\n",
    "\n",
    "script_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "path = os.path.join(script_dir, '../Data/' + main_publisher + '/')\n",
    "\n",
    "df_chapters = pd.read_csv(path + 'chapters.csv', delimiter = '|')\n",
    "df_chapters_embeddings = pd.read_csv(path + 'embeddings_chapters.csv', delimiter = '|', index_col=0)\n",
    "df_concepts = pd.read_csv(path + 'concepts_bis.csv', delimiter = '|')\n",
    "df_concepts_embeddings = pd.read_csv(path + 'embeddings_concepts_bis.csv', delimiter = '|', index_col=0)\n",
    "df_classes = pd.read_csv(path + 'classes.csv', delimiter = '|')\n",
    "df_classes_embeddings = pd.read_csv(path + 'embeddings_classes_bis.csv', delimiter = '|', index_col=0)\n",
    "df_precedences_episodes = pd.read_csv(path + 'precedences_episodes.csv', delimiter = '|')\n",
    "df_precedences_series = pd.read_csv(path + 'precedences_series.csv', delimiter = '|')\n",
    "\n",
    "df_concepts['Concept'] = df_concepts['Concept'].apply(lambda x : x.split('/')[-1])\n",
    "\n",
    "df_classes = df_classes.dropna()\n",
    "print(f'{df_chapters[\"Cid\"].isna().sum().sum():04d} NaN values in chapters.')\n",
    "print(f'{df_concepts.isna().sum().sum():04d} Nan values in concepts.')\n",
    "print(f'{df_classes.isna().sum().sum():04d} Nan values in classes.')\n",
    "print(f'{df_precedences_episodes.isna().sum().sum():04d} Nan values in episdes precedences.')\n",
    "print(f'{df_precedences_series.isna().sum().sum():04d} Nan values in series precedences.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "unique_oer_id = id_mapper(df_chapters['Cid'], 'OER')\n",
    "unique_concept_id =  id_mapper(df_concepts['Concept'], 'Concept')\n",
    "unique_class_id =  id_mapper(df_classes['Class'], 'Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16786])\n",
      "torch.Size([2, 16786])\n",
      "torch.Size([2, 2097])\n",
      "torch.Size([2, 423])\n",
      "torch.Size([2, 58295])\n",
      "torch.Size([2, 58295])\n"
     ]
    }
   ],
   "source": [
    "oer_covers_concept_subject = edge_construction(df1 = df_concepts, df2 = unique_oer_id, col = 'mappedID', \n",
    "                                       how = 'left', right_on = 'OER')\n",
    "oer_covers_concept_pr = edge_construction(df1 = df_concepts, df2 = unique_oer_id, col = 'PR', \n",
    "                                          how = 'right', right_on = 'OER')\n",
    "oer_covers_concept_object = edge_construction(df1 = df_concepts, df2 = unique_concept_id, col = 'mappedID', \n",
    "                                       how = 'left', right_on = 'Concept')\n",
    "\n",
    "oer_before_oer_ep_subject = edge_construction(df1 = df_precedences_episodes, df2 = unique_oer_id, col = 'mappedID', \n",
    "                                   how = 'left', left_on = 'Before', right_on = 'OER')\n",
    "oer_before_oer_ep_object = edge_construction(df1 = df_precedences_episodes, df2 = unique_oer_id, col = 'mappedID', \n",
    "                                   how = 'left', left_on = 'After', right_on = 'OER')\n",
    "oer_before_oer_sr_subject = edge_construction(df1 = df_precedences_series, df2 = unique_oer_id, col = 'mappedID', \n",
    "                                   how = 'left', left_on = 'Before', right_on = 'OER')\n",
    "oer_before_oer_sr_object = edge_construction(df1 = df_precedences_series, df2 = unique_oer_id, col = 'mappedID', \n",
    "                                   how = 'left', left_on = 'After', right_on = 'OER')\n",
    "\n",
    "concept_belongs_class_subject = edge_construction(df1 = df_classes, df2 = unique_concept_id, col = 'mappedID', \n",
    "                                   how = 'left', left_on = 'Concept', right_on = 'Concept')\n",
    "concept_belongs_class_object = edge_construction(df1 = df_classes, df2 = unique_class_id, col = 'mappedID', \n",
    "                                   how = 'left', left_on = 'Class', right_on = 'Class')\n",
    "\n",
    "oer_covers_concept = torch.stack([oer_covers_concept_subject, oer_covers_concept_object], dim = 0).long()\n",
    "oer_covers_concept_rev = torch.stack([oer_covers_concept_object, oer_covers_concept_subject], dim = 0).long()\n",
    "oer_before_oer_ep = torch.stack([oer_before_oer_ep_subject, oer_before_oer_ep_object], dim = 0).long()\n",
    "oer_before_oer_sr = torch.stack([oer_before_oer_sr_subject, oer_before_oer_sr_object], dim = 0).long()\n",
    "concept_belongs_class = torch.stack([concept_belongs_class_subject, concept_belongs_class_object], dim = 0).long()\n",
    "concept_belongs_class_rev = torch.stack([concept_belongs_class_object, concept_belongs_class_subject], dim = 0).long()\n",
    "print(oer_covers_concept.shape)\n",
    "print(oer_covers_concept_rev.shape)\n",
    "print(oer_before_oer_ep.shape)\n",
    "print(oer_before_oer_sr.shape)\n",
    "print(concept_belongs_class.shape)\n",
    "print(concept_belongs_class_rev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters_embeddings_tmp = {}\n",
    "concepts_embeddings_tmp = {} \n",
    "classes_embeddings_tmp = {}\n",
    "\n",
    "chapters_r = range(len(df_chapters['Cid'].unique()))\n",
    "concepts_c = range(len(df_concepts['Concept'].unique()))\n",
    "classes_c = range(len(df_classes['Class'].unique()))\n",
    "\n",
    "chapters_embeddings = np.zeros(shape=(len(chapters_r), 768))\n",
    "concepts_embeddings = np.zeros(shape=(len(concepts_c), 768))\n",
    "classes_embeddings = np.zeros(shape=(len(classes_c), 768))\n",
    "\n",
    "\n",
    "i = 0\n",
    "for r in chapters_r:\n",
    "    chapters_embeddings_tmp[r] = list(filter(None, df_chapters_embeddings['BERT'][r].strip(\"[]\\n\").replace(\"'\",\"\").split(\" \")))\n",
    "    chapters_embeddings_tmp[r] = [float(f) for f in chapters_embeddings_tmp[r]]\n",
    "    for a in range(len(chapters_embeddings_tmp[r])):\n",
    "            chapters_embeddings[i][a] = chapters_embeddings_tmp[r][a]\n",
    "    i += 1\n",
    "\n",
    "i = 0\n",
    "for r in concepts_c:\n",
    "    concepts_embeddings_tmp[r] = list(filter(None, df_concepts_embeddings['BERT'][r].strip(\"[]\\n\").replace(\"'\",\"\").split(\" \")))\n",
    "    concepts_embeddings_tmp[r] = [float(f) for f in concepts_embeddings_tmp[r]]\n",
    "    for a in range(len(concepts_embeddings_tmp[r])):\n",
    "            concepts_embeddings[i][a] = concepts_embeddings_tmp[r][a]\n",
    "    i += 1   \n",
    "\n",
    "i = 0\n",
    "for r in classes_c:\n",
    "    classes_embeddings_tmp[r] = list(filter(None, df_classes_embeddings['BERT'][r].strip(\"[]\\n\").replace(\"'\",\"\").split(\" \")))\n",
    "    classes_embeddings_tmp[r] = [float(f) for f in classes_embeddings_tmp[r]]\n",
    "    for a in range(len(classes_embeddings_tmp[r])):\n",
    "            classes_embeddings[i][a] = classes_embeddings_tmp[r][a]\n",
    "    i += 1\n",
    "\n",
    "chapters_embeddings = torch.from_numpy(chapters_embeddings).to(torch.float32)\n",
    "concepts_embeddings = torch.from_numpy(concepts_embeddings).to(torch.float32)\n",
    "classes_embeddings = torch.from_numpy(classes_embeddings).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abazouzi/Documents/Code/PrerequisiteLearning/clara-datasets/lib64/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2097])\n",
      "HeteroData(\n",
      "  \u001b[1mOER\u001b[0m={\n",
      "    node_id=[2550],\n",
      "    x=[2550, 768]\n",
      "  },\n",
      "  \u001b[1mConcept\u001b[0m={\n",
      "    node_id=[6007],\n",
      "    x=[6007, 768]\n",
      "  },\n",
      "  \u001b[1mClass\u001b[0m={\n",
      "    node_id=[292],\n",
      "    x=[292, 768]\n",
      "  },\n",
      "  \u001b[1m(OER, covers, Concept)\u001b[0m={\n",
      "    edge_index=[2, 16786],\n",
      "    edge_attr=[16830]\n",
      "  },\n",
      "  \u001b[1m(Concept, rev_covers, OER)\u001b[0m={ edge_index=[2, 16786] },\n",
      "  \u001b[1m(OER, before_sr, OER)\u001b[0m={ edge_index=[2, 423] },\n",
      "  \u001b[1m(OER, before_ep, OER)\u001b[0m={ edge_index=[2, 2097] },\n",
      "  \u001b[1m(Concept, belongs, Class)\u001b[0m={ edge_index=[2, 58295] },\n",
      "  \u001b[1m(Class, rev_belongs, Concept)\u001b[0m={ edge_index=[2, 58295] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "data = HeteroData()\n",
    "data['OER'].node_id = torch.tensor(unique_oer_id['mappedID'].values)\n",
    "data['OER'].x = chapters_embeddings\n",
    "data['Concept'].node_id = torch.tensor(unique_concept_id['mappedID'].values)\n",
    "data['Concept'].x = concepts_embeddings\n",
    "data['Class'].node_id = torch.tensor(unique_class_id['mappedID'].values)\n",
    "data['Class'].x = classes_embeddings\n",
    "data['OER', 'covers', 'Concept'].edge_index = oer_covers_concept\n",
    "data['Concept', 'rev_covers', 'OER'].edge_index = oer_covers_concept_rev\n",
    "\n",
    "data['OER', 'covers', 'Concept'].edge_attr = oer_covers_concept_pr\n",
    "print(oer_before_oer_ep.shape)\n",
    "data['OER', 'before_sr', 'OER'].edge_index = oer_before_oer_sr\n",
    "data['OER', 'before_ep', 'OER'].edge_index = oer_before_oer_ep\n",
    "data['Concept', 'belongs', 'Class'].edge_index = concept_belongs_class\n",
    "data['Class', 'rev_belongs', 'Concept'].edge_index = concept_belongs_class_rev\n",
    "\n",
    "#data = T.ToUndirected()(data)\n",
    "data.validate()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def seed_everything(seed=0):                                                  \n",
    "       random.seed(seed)                                                            \n",
    "       torch.manual_seed(seed)                                                      \n",
    "       torch.cuda.manual_seed_all(seed)                                             \n",
    "       np.random.seed(seed)                                                         \n",
    "       os.environ['PYTHONHASHSEED'] = str(seed)                                     \n",
    "       torch.backends.cudnn.deterministic = True                                    \n",
    "       torch.backends.cudnn.benchmark = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610\t Edges for training\n",
      "75\t Edges for validation\n",
      "75\t Edges for testing\n",
      "tensor([1692, 1554, 2541, 1480,  422])\n",
      "tensor([2187,  412, 1881, 1991,  541])\n",
      "tensor([2529,  769, 2363, 1027, 1958])\n",
      "tensor([1693, 1555, 2542, 1481,  423])\n",
      "tensor([2188,  413, 1882, 1992,  542])\n",
      "tensor([2530,  770, 2364, 1028, 1959])\n"
     ]
    }
   ],
   "source": [
    "agnostic = False\n",
    "if agnostic:\n",
    "    num_val = 0.5\n",
    "    num_test = 0.5\n",
    "else:\n",
    "    num_val = 0.1\n",
    "    num_test = 0.1\n",
    "seed_everything()\n",
    "transform = T.RandomLinkSplit(\n",
    "    num_val = num_val,\n",
    "    num_test = num_test,\n",
    "    disjoint_train_ratio = 0.0,\n",
    "    neg_sampling_ratio = 0.8,\n",
    "    add_negative_train_samples = True,\n",
    "    edge_types=('OER', 'before_sr', 'OER')\n",
    ")\n",
    "\n",
    "train_data, val_data, test_data = transform(data)\n",
    "print(f'{len(train_data[\"OER\", \"before_sr\", \"OER\"].edge_label.detach().numpy())}\\t Edges for training')\n",
    "print(f'{len(val_data[\"OER\", \"before_sr\", \"OER\"].edge_label.detach().numpy())}\\t Edges for validation')\n",
    "print(f'{len(test_data[\"OER\", \"before_sr\", \"OER\"].edge_label.detach().numpy())}\\t Edges for testing')\n",
    "print(train_data[\"OER\", \"before_sr\", \"OER\"].edge_label_index[0][:5])\n",
    "print(val_data[\"OER\", \"before_sr\", \"OER\"].edge_label_index[0][:5])\n",
    "print(test_data[\"OER\", \"before_sr\", \"OER\"].edge_label_index[0][:5])\n",
    "print(train_data[\"OER\", \"before_sr\", \"OER\"].edge_label_index[1][:5])\n",
    "print(val_data[\"OER\", \"before_sr\", \"OER\"].edge_label_index[1][:5])\n",
    "print(test_data[\"OER\", \"before_sr\", \"OER\"].edge_label_index[1][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760\n",
      "760\n",
      "760\n",
      "1059\n"
     ]
    }
   ],
   "source": [
    "seed_everything()\n",
    "cross_val_data = {}\n",
    "cross_val_data[\"OER\", \"before_sr\", \"OER\"] = {}\n",
    "print(len(train_data[\"OER\", \"before_sr\", \"OER\"].edge_label_index[0]) + \n",
    "      len(val_data[\"OER\", \"before_sr\", \"OER\"].edge_label_index[0]) +\n",
    "      len(test_data[\"OER\", \"before_sr\", \"OER\"].edge_label_index[0]))\n",
    "\n",
    "cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label\"] = torch.cat(\n",
    "    [train_data[\"OER\", \"before_sr\", \"OER\"].edge_label, \n",
    "     val_data[\"OER\", \"before_sr\", \"OER\"].edge_label,\n",
    "     test_data[\"OER\", \"before_sr\", \"OER\"].edge_label], \n",
    "    dim = 0).long()\n",
    "cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"] = torch.cat(\n",
    "    [train_data[\"OER\", \"before_sr\", \"OER\"].edge_label_index, \n",
    "     val_data[\"OER\", \"before_sr\", \"OER\"].edge_label_index,\n",
    "     test_data[\"OER\", \"before_sr\", \"OER\"].edge_label_index], \n",
    "    dim = 1).long()\n",
    "cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_index\"] = torch.cat(\n",
    "    [train_data[\"OER\", \"before_sr\", \"OER\"].edge_index, \n",
    "     val_data[\"OER\", \"before_sr\", \"OER\"].edge_index,\n",
    "     test_data[\"OER\", \"before_sr\", \"OER\"].edge_index],\n",
    "    dim = 1).long()\n",
    "print(len(cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label\"]))\n",
    "print(len(cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][0]))\n",
    "print(len(cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_index\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   3, 1603,  545, 1779, 1460, 1287,  331, 1212,  402,  587, 1371, 1932,\n",
      "        1559, 1114,  876, 2440,   48, 2233, 1376, 1706, 1384,  795, 1875, 1043,\n",
      "         519,  824, 1455, 2348, 1907, 1973,  749, 1662, 1791, 1159, 1280, 1996,\n",
      "        1221,  782, 1430,  515, 1985,   53, 2321, 1096, 2333, 2301, 2225,  264,\n",
      "        1864, 1287, 1554, 1070,  374, 1018, 1682, 1024, 2303, 1333, 2010, 2275,\n",
      "        1894, 1072,  443, 1044, 2083, 1814,  264,  957,  591,  916,  933,  734,\n",
      "         541, 1119, 1176,  200, 1040,  306,  853, 2194, 2232, 1671, 2073, 2329,\n",
      "         525, 1914,  907,  960, 1322, 1303, 1759, 1284,  185, 1363, 2141, 2343,\n",
      "         634, 1482,  129,  787, 2260, 1225, 1933, 1353,  743, 2541, 2403, 1935,\n",
      "         301,  852, 2250, 1768,  518, 2179,  985, 2004, 2325, 2161, 1246, 1067,\n",
      "        1027, 2336,  434,  407,  662,  169, 2092, 1686, 1502, 2360, 2546,  656,\n",
      "         730, 1527,  502,  627,  799, 2212, 2523,  678, 1050,   21, 1040, 1367,\n",
      "         428, 2417,  204, 1323,  148, 1094, 1152,  924, 2376, 1109, 1448, 1982,\n",
      "        2012, 2325, 2256,  164,  692, 2016,  504,  411, 1536, 1981,  811,  475,\n",
      "        1348,  210,  385,  458,  968, 1126, 1379, 2529, 1084, 2356,  607, 1494,\n",
      "         530, 1844,  535, 1734, 1514, 2216,  481, 1253, 1312,  381,   51, 1506,\n",
      "         754, 1373,  905,  639,  334,  870,  385,  426, 1266, 2164, 2110, 1899,\n",
      "          40,   48,   16, 1237, 1574,  309, 1966, 1105,  520,  955, 1464, 2013,\n",
      "        2198, 2310, 1218, 2206,  825,  824, 1394, 2227, 1818,   74,  207, 1985,\n",
      "        2042, 2167, 1170, 1060, 1801, 1585, 2369, 2456,  694, 2043, 1065,  924,\n",
      "        2016,  856, 2176, 2172, 2190, 1577, 1507,  597, 1599, 1267,  672, 2394,\n",
      "         497, 2078,   47,  583, 1881,  201, 1054, 1987, 2320, 1970, 1740, 2234,\n",
      "         887, 2103, 2073, 1362, 2217, 1941,  561, 2468, 2089, 2198,  657, 2146,\n",
      "         857,  708,  346, 2213,   85, 2407, 2016,  668, 1657, 1547,  364, 1851,\n",
      "         406, 1569, 2494,  350, 2087,  553, 1267,   92, 1791,    5, 1621,  283,\n",
      "        1692, 2264,   57,  312, 2007, 2062,  569, 1995, 1232, 1752, 2333, 1324,\n",
      "        2488, 2301, 1399, 2313, 2128,  626, 1104,  301,  800,  271, 1787, 2043,\n",
      "         992, 1095,  608,  790,  621, 1480,  141,   67, 1778, 2000,  856, 1541,\n",
      "        1615,  725, 1624, 1553, 1728, 1299, 1668, 1276,  469, 1962, 1847, 1278,\n",
      "         736,  557, 2322, 1537,  927, 2541, 1200,   71,  459,  941, 1795, 1435,\n",
      "         849, 1274, 1869, 2498,  785, 1830,  369, 2525,  673, 1474, 2389, 2114,\n",
      "         330, 2432, 2517,  825,  410,  640, 1929, 2290, 1032,  891,  483, 1875,\n",
      "           0, 1869,  373,  486,  242,  492, 1466,  191, 1037, 1758,  776, 1454,\n",
      "        1992, 1289, 1726,  230,  669, 2097,  276, 2407,  133, 1699, 2306, 1964,\n",
      "        1867,  177,  689,   80, 2509, 1203,  864, 2368,  832,  463, 1805,  300,\n",
      "         204,  108,  855,   39,  563, 1021,  325, 1568,  946, 1094,  332, 2182,\n",
      "         240,  259, 2024,  526, 1872, 1844,  422, 2220, 2239, 2486, 1742, 2487,\n",
      "        1987,  318,  632,  292, 2273,  227, 2401, 2475,  769, 2020,  355, 1820,\n",
      "        1402, 1409, 1892,  385,  901, 2363, 2129,   87,  614, 1942, 1184, 2337,\n",
      "        1858, 1435, 2363, 1456, 1164, 1978,   46, 2283,  295,  575, 2508,  409,\n",
      "        1942,  103,  806, 1074, 1383, 2308,  381, 2056, 2424, 1657,   73,  236,\n",
      "         127,  134, 1962, 1715, 2296, 1151,  683,  593, 1962,  532, 1053, 1919,\n",
      "        2304, 1719, 1139, 1867, 1888, 2382, 1343,  358, 1806, 1103, 1958,  128,\n",
      "        2442,  390,  668, 2109, 2135, 2242,  468,  193, 2315, 1713,  126, 1908,\n",
      "        1640, 1552, 1991, 2287, 1486, 1610,  855, 1465,  718, 2161, 1736, 1164,\n",
      "        1609, 1287,  729, 2268, 2035,  447,  838, 1146, 1404,  418, 1090, 2031,\n",
      "        1786, 1521,  331,  430,  481, 2309,  775, 2027,  976, 1717, 2463, 2085,\n",
      "        1247, 2294, 1041, 2039, 1182,  628, 2321, 2141, 1567, 2035, 1812, 1428,\n",
      "        1294, 2175, 1922, 1674, 2493, 1534, 1314,  992,  699, 1123, 2068,  243,\n",
      "        1956, 2494,   99, 1026,  650,  260, 1177,  726, 1069,  451,   43,  908,\n",
      "         618,  393,  644, 1400,  301, 1602, 1001, 2429,  150, 2235,  274,  895,\n",
      "        1099,   76, 1086, 2151,  119,  379,  702, 2534,  723, 1242, 2008,  359,\n",
      "        2156, 1175, 2298, 1802, 1627,  603, 1895,   10,  623, 1660, 1805, 1954,\n",
      "        1471, 2135, 1277, 1441,   61, 1338,  819,  762,   28,  442, 1157, 1600,\n",
      "        2337, 1884,  267, 1366,  150,  153,  458, 1568,  614, 1745, 1178, 1100,\n",
      "         605, 1673,  492,  511,  796, 2298, 2187, 1779,  557, 1994,   11, 2083,\n",
      "        2448, 2107,  394, 1468, 1259, 1474,  108, 2435,  998, 1414,  788, 2501,\n",
      "         802,  113, 2087, 1837, 1375, 2051, 1363,  412, 1380, 1078,  717, 2295,\n",
      "         220, 2244,  213, 1357, 2319, 1023,  620, 1774,  438, 2249,  202, 1680,\n",
      "        1547,  265,   24, 1388,  881, 2252, 2119, 2393, 1348, 1980, 1292,  159,\n",
      "        2399,  435, 2355,  230, 2271, 1634,  547, 1224,  506, 1332, 2411,   43,\n",
      "        1218,  719, 1134, 1195,  951,  947, 1020, 2057, 1207, 2405,    5, 1179,\n",
      "          34,  249, 2236,  429,  990, 1902, 2387,  398, 2504, 1426, 1800, 2279,\n",
      "        1310, 2240, 2097, 1842])\n",
      "tensor([1940, 1433,  578, 1780, 1461, 1867,  238, 1213,  403,  588, 1372,   71,\n",
      "        1560, 1115,  877, 1216, 1207, 1632,  914, 1707,  194,  796,  189,  974,\n",
      "         520, 1024, 1605, 2349, 1891, 1974,  750, 1663,  118,  391, 1281, 1997,\n",
      "        1222,  783, 1431,  516, 1986,  875,  116,  836,  756, 1095,  866, 1893,\n",
      "        1865, 1700, 1555,  581,  375, 1019, 1465, 2423, 2304, 1334, 1001, 2276,\n",
      "        1104, 1688, 1893, 1045, 1166,  478,  235, 2453,  592,  917,  934,  514,\n",
      "         542, 1120,  192, 2262, 1491, 2428,  256, 2195, 2429, 1535, 2074, 2330,\n",
      "         526, 1915,  243,  961,  905, 1304, 1760, 1285,  186, 2104, 2173, 2344,\n",
      "         635, 1980, 1512, 2304, 2261, 1226, 2073, 1354,  744, 2542,  773, 1936,\n",
      "        1417,  203, 2424, 1769, 2389,  630,  986, 2005,  641,   69,  276,  850,\n",
      "        1028, 2337,  435, 1865,  663,  170, 2093, 1687, 1503, 1711, 2547,  173,\n",
      "         731, 1528,  503,  628, 2080, 2213, 2524,  679, 1051,   22, 1327, 1368,\n",
      "        1430, 2418, 2444, 2134, 2199,  909, 2031,  925, 2377, 1110, 1449, 1983,\n",
      "        2013, 2326, 2257,  195, 2536, 1613, 2224,  412, 1311, 1803,  812,  476,\n",
      "        1349,  628, 1888,  871,  969, 1352, 1380, 2530, 1085, 2357,  608, 1495,\n",
      "         531, 1845,  536, 1735, 1515,  333,  482, 1254, 1286, 2297,   52, 1507,\n",
      "         755, 2342, 1791,  640,   79,  871,  386,  427, 1751,  448,  358, 1900,\n",
      "        2364,   49,   17, 1238, 1575,  310, 1967, 1228, 1671, 1166, 1102, 1827,\n",
      "        2199, 2311, 1219, 2207,  826, 2542, 1395, 2228,  822, 2489,  708,  122,\n",
      "         911, 2168, 1171, 1061, 1518, 1694, 2370, 2457,  695, 2364, 1066,  943,\n",
      "        2017,  857, 2177, 2111, 1196,  330,  255,  598,  405, 1268, 2356, 2395,\n",
      "         498, 2079,   82,  584, 1882,   68, 1055, 1666, 1733, 1971, 1741, 2235,\n",
      "         888, 2104, 1982, 1363,  903,    1,  115, 2469, 1904, 2173,  658, 2147,\n",
      "         674,  547,  347, 1581,   86, 1648, 1529,  669, 1116, 1548,  365, 1852,\n",
      "         407, 2068,  976,  351,  345,  554, 2089,   93,  823,    6,  763,  284,\n",
      "        1693, 2265,   58,  210, 2346, 2063,  570, 1080, 1233, 1619, 2334, 1325,\n",
      "        2489, 1098, 1400, 2314, 2535, 1340, 1105,  576,  801,  215, 1788, 2044,\n",
      "         993,  158, 1866,  649,  622, 1481,  142,   68,  105, 2001,  211, 1542,\n",
      "        1616, 1333,  855, 2024, 1729, 1300, 1669, 2401,  470,  878, 1402, 2546,\n",
      "         737, 1444, 2323,  767, 1305,  554, 1201,  522, 2282,  942, 1796, 1436,\n",
      "         850, 1275, 1919, 2499,  690, 1831,  370,  759,  674,  615, 2390, 2115,\n",
      "         331,  148, 2518, 2051, 1899,  988, 1930, 2291, 1033, 2473, 1635, 1876,\n",
      "         581, 1870,  374,  487, 1739,  493, 1467,  107, 1038,   35,  777, 1455,\n",
      "        1729, 1290,  871,  969, 1086, 2098,  277,  733,  591, 1700, 2307,   13,\n",
      "        1320,  178,  690,   81, 2510, 1204,  865, 1288,  833,  464,  727,  475,\n",
      "        1713,  109,  972,   40,  564,  435,   61, 1153, 1691, 1095,  320, 2183,\n",
      "         241,  260, 2025, 2073, 2336, 2300,  423, 2221, 1984,  651, 1193,  782,\n",
      "        1988,  319, 2242,  293, 1164,  907, 2123, 2476,  770, 2021,  356, 1821,\n",
      "         949, 1410, 1893, 1229,  902, 2364, 2130, 2186, 1315, 1943, 1185, 1024,\n",
      "        1859,  193,  684, 2238,  780, 1979,  537, 2284, 1547,  818,  625, 1369,\n",
      "        1450, 2076,  807, 1075, 1384, 1652,  382, 2057, 2425, 1658,   74, 2179,\n",
      "         426,  135, 1963, 1897,  203, 1152,  684, 1060, 2541, 2502,  715, 2233,\n",
      "        1021, 1720, 1140, 1642, 1425, 2383, 1344, 2302, 1807,  905, 1959,  131,\n",
      "        2443,  391, 1849, 2110, 1533,  138, 2398,  194, 1646, 1714,  127, 1909,\n",
      "        1641,  232, 1992, 2288, 1487,  545, 2115, 1600, 2249, 2162,  540, 1165,\n",
      "        1610, 1139, 1567, 2269,   40,  448,  839, 1147, 1405,  419, 1091, 2032,\n",
      "        2416, 1522, 1024,  431, 1675, 1732,   56, 2028,  977,  459,  567, 1597,\n",
      "        1248, 2295, 1042, 2040,  280, 2015,  534, 2142, 1568, 2036, 1813, 2126,\n",
      "        1295, 2176, 1923, 1675,  585, 1535, 1315,  110,  700, 1124, 2069, 1324,\n",
      "        1828, 2495,  100, 2461,  651,  580, 1178, 1877, 1070,  452, 1155,  909,\n",
      "        1788, 2322,  645, 1750,  302, 1603, 1002, 2430,  980, 1762, 1747,  896,\n",
      "        1100,   77, 1682, 2152, 1948, 1553, 1777, 2535,  724, 1243, 2009,  360,\n",
      "        2157,  930, 2299, 1803, 1638,  604, 1088,   11,  703, 2281, 1879, 1955,\n",
      "        1472, 2136, 1278, 1442,   62, 1339,  820,  763,   29,  443, 1158, 2190,\n",
      "        1834, 1885,  268,  491,  151, 2420,  459,  599,  615, 1746,  813, 1265,\n",
      "         257, 1971,  411,  512, 1939, 2535, 2188,  209,  558, 1995,  422, 2084,\n",
      "        2449, 1517,  395, 2447, 1260, 2006, 1301, 2436,  469, 1415,  789, 2502,\n",
      "        1775,  114, 2088, 1838, 1376, 2052, 2006,  413,  757, 1079,  718, 2531,\n",
      "         221, 2245,  214, 1358, 2320, 1024, 1046, 1775,  439,  899,  203, 1681,\n",
      "        1156, 1670,   25, 1389,  882, 2253, 2120,   63, 2484, 2101, 1293,  160,\n",
      "        2400, 1370,  155,  231, 2272, 1635,  548, 1091,  507, 1566, 2412,   44,\n",
      "         276, 2475, 1135, 1196,  952,  992, 1727, 1816, 1208, 2406,   42, 2509,\n",
      "          35,  250,  280, 1375, 1978, 1903, 1928,  399, 2505, 1427, 2299, 2280,\n",
      "        1311, 2241, 1640,  799])\n",
      "tensor([0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
      "        1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
      "        1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
      "        0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
      "        1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0,\n",
      "        1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1,\n",
      "        1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n",
      "        1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1,\n",
      "        1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "        1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
      "        1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
      "        0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
      "        0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
      "        1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0,\n",
      "        1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
      "        0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
      "        1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
      "        1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
      "        1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
      "        1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "seed_everything()\n",
    "num_samples = len(cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label\"])\n",
    "shuffled_index = np.arange(num_samples)\n",
    "np.random.shuffle(shuffled_index)\n",
    "cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][0] = cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][0][shuffled_index]\n",
    "cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][1] = cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][1][shuffled_index]\n",
    "cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label\"] = cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label\"][shuffled_index]\n",
    "print(cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][0])\n",
    "print(cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][1])\n",
    "print(cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = 5\n",
    "chunk_size = int(len(cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label\"]) / cv)\n",
    "cross_val_chunks = []\n",
    "for n in range(cv):\n",
    "    cross_val_chunk = {}\n",
    "    cross_val_chunk[\"OER\", \"before_sr\", \"OER\"] = {}\n",
    "    cross_val_chunk[\"OER\", \"before_sr\", \"OER\"][\"edge_label\"] = {}\n",
    "    begin = n * chunk_size\n",
    "    if n == cv - 1:\n",
    "        end = len(cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label\"])\n",
    "    else :\n",
    "        end = (n+1) * chunk_size\n",
    "    cross_val_chunk[\"OER\", \"before_sr\", \"OER\"][\"edge_label\"] = cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label\"][begin : end]\n",
    "    cross_val_chunk[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"] = []\n",
    "    cross_val_chunk[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"].append(cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][0][begin : end])\n",
    "    cross_val_chunk[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"].append(cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][1][begin : end])\n",
    "    cross_val_chunks.append(cross_val_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_data_train = []\n",
    "cross_val_data_test = []\n",
    "for n in range(cv) :\n",
    "    cross_val_data_train_chunk = {}\n",
    "    cross_val_data_train_chunk[\"OER\", \"before_sr\", \"OER\"] = {}\n",
    "    cross_val_data_train_chunk[\"OER\", \"before_sr\", \"OER\"][\"edge_label\"] = torch.cat(\n",
    "    [cross_val_chunks[(n+1)%cv][\"OER\", \"before_sr\", \"OER\"][\"edge_label\"], \n",
    "     cross_val_chunks[(n+2)%cv][\"OER\", \"before_sr\", \"OER\"][\"edge_label\"],\n",
    "     cross_val_chunks[(n+3)%cv][\"OER\", \"before_sr\", \"OER\"][\"edge_label\"],\n",
    "     cross_val_chunks[(n+4)%cv][\"OER\", \"before_sr\", \"OER\"][\"edge_label\"]\n",
    "     ], \n",
    "    dim = 0).long()\n",
    "    cross_val_data_test_chunk = {}\n",
    "    cross_val_data_test_chunk[\"OER\", \"before_sr\", \"OER\"] = {}\n",
    "    cross_val_data_test_chunk[\"OER\", \"before_sr\", \"OER\"][\"edge_label\"] = cross_val_chunks[n][\"OER\", \"before_sr\", \"OER\"][\"edge_label\"]\n",
    "\n",
    "    cross_val_data_train_chunk[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"] = []\n",
    "    cross_val_data_train_chunk[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"].append(torch.cat(\n",
    "    [cross_val_chunks[(n+1)%cv][\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][0], \n",
    "     cross_val_chunks[(n+2)%cv][\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][0],\n",
    "     cross_val_chunks[(n+3)%cv][\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][0],\n",
    "     cross_val_chunks[(n+4)%cv][\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][0]\n",
    "     ], \n",
    "    dim = 0).long())\n",
    "    cross_val_data_train_chunk[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"].append(torch.cat(\n",
    "    [cross_val_chunks[(n+1)%cv][\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][1], \n",
    "     cross_val_chunks[(n+2)%cv][\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][1],\n",
    "     cross_val_chunks[(n+3)%cv][\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][1],\n",
    "     cross_val_chunks[(n+4)%cv][\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][1]\n",
    "     ], \n",
    "    dim = 0).long())\n",
    "    cross_val_data_test_chunk[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"] = []\n",
    "    cross_val_data_test_chunk[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"].append(\n",
    "        cross_val_chunks[n][\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][0])\n",
    "    cross_val_data_test_chunk[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"].append(\n",
    "        cross_val_chunks[n][\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][1])\n",
    "    \n",
    "    cross_val_data_train.append(cross_val_data_train_chunk)\n",
    "    cross_val_data_test.append(cross_val_data_test_chunk)\n",
    "\n",
    "len(cross_val_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, epochs, lr, verbose = False):\n",
    "    total_loss = 0\n",
    "    loss_values = []\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    train_data.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "    duration = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(train_data)\n",
    "        ground_truth = train_data[\"OER\", \"before_sr\", \"OER\"].edge_label\n",
    "        assert pred.shape == ground_truth.shape, f'ERROR : Shapes differ between prediction and ground truth ! ({pred.shape, ground_truth.shape})'\n",
    "        loss = F.binary_cross_entropy_with_logits(pred.float(), ground_truth.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss)\n",
    "        loss_values.append(loss.item())\n",
    "        if verbose and epoch % 10 == 0:\n",
    "            print(f\"Epoch : {epoch:03d}, Loss : {total_loss : .4f}\")\n",
    "    duration = time.time() - duration\n",
    "    \n",
    "    return {\n",
    "        'Loss_values' : loss_values,\n",
    "        'Loss' : total_loss,\n",
    "        'Duration' : duration,\n",
    "        'Model' : model\n",
    "    }\n",
    "def predict(model, test_data):\n",
    "\n",
    "    preds = model(test_data).detach().numpy()\n",
    "    preds_labels = (preds > 0.5) * 1\n",
    "    ground_truths = test_data[\"OER\", \"before_sr\", \"OER\"].edge_label\n",
    "    assert preds.shape == ground_truths.shape, f'ERROR : Shapes differ between prediction and ground truth ! ({preds.shape, ground_truths.shape})'\n",
    "    #auc_score = roc_auc_score(ground_truths, preds)\n",
    "    precision = precision_score(ground_truths, preds_labels, zero_division = np.nan)\n",
    "    accuracy = accuracy_score(ground_truths, preds_labels)\n",
    "    f1 = f1_score(ground_truths, preds_labels, average='macro')\n",
    "    recall = recall_score(ground_truths, preds_labels, average='macro')\n",
    "    return {\n",
    "        #'AUC' : auc_score,\n",
    "        'Precision' : precision,\n",
    "        'Accuracy' : accuracy,\n",
    "        'Recall' : recall,\n",
    "        'F1' : f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_channels_selected = 16\n",
    "entity_features = 768\n",
    "num_layers_selected = 6\n",
    "epochs_selected = 300 #300 the best\n",
    "learning_rates_selected = 0.01\n",
    "\n",
    "selected_params = [{\n",
    "    'epochs': epochs_selected, \n",
    "    'hidden_channels': hidden_channels_selected, \n",
    "    'num_layers': num_layers_selected, #8 is too much => generated NaN values in node attributes\n",
    "    'lr': learning_rates_selected, \n",
    "    'entity_features': entity_features\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import HeteroConv, SAGEConv, GATConv, Linear, SimpleConv, GATv2Conv, MLP\n",
    "from torch_geometric.data import HeteroData\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import os\n",
    "\n",
    "class ModelSAGE(torch.nn.Module):\n",
    "    def __init__(self, node_types, heads, hidden_channels, out_channels, entity_features, num_layers):\n",
    "        super().__init__()\n",
    "        self.gnn = self.HeteroGNN(node_types, heads, hidden_channels, out_channels, num_layers)\n",
    "        self.gnn = self.gnn.float()\n",
    "        self.classifier = self.Classifier(hidden_channels + entity_features)\n",
    "\n",
    "    def forward(self, data : HeteroData) -> Tensor:\n",
    "        node_dict_emb = {\n",
    "            \"OER\" : data[\"OER\"].x,\n",
    "            \"Concept\" : data[\"Concept\"].x,\n",
    "            \"Class\" : data[\"Class\"].x\n",
    "        }\n",
    "        node_dict = {\n",
    "            \"OER\" : data[\"OER\"].x,\n",
    "            \"Concept\" : data[\"Concept\"].x,\n",
    "            \"Class\" : data[\"Class\"].x\n",
    "        }\n",
    "        edge_dict = {\n",
    "            (\"OER\", \"before_sr\", \"OER\"): data[\"OER\", \"before_sr\", \"OER\"].edge_label_index,\n",
    "            (\"OER\", \"before_ep\", \"OER\"): data[\"OER\", \"before_ep\", \"OER\"].edge_index,\n",
    "            (\"OER\", \"covers\", \"Concept\") : data[\"OER\", \"covers\", \"Concept\"].edge_index,\n",
    "            (\"Concept\", \"belongs\", \"Class\") : data[\"Concept\", \"belongs\", \"Class\"].edge_index,\n",
    "            (\"Concept\", \"rev_covers\", \"OER\") : data[\"Concept\", \"rev_covers\", \"OER\"].edge_index,\n",
    "            (\"Class\", \"rev_belongs\", \"Concept\") : data[\"Class\", \"rev_belongs\", \"Concept\"].edge_index\n",
    "        }\n",
    "\n",
    "        node_dict_emb = self.gnn(node_dict_emb, edge_dict)\n",
    "        node_dict = {\n",
    "            \"OER\" : torch.cat((data[\"OER\"].x, node_dict_emb[\"OER\"]), dim = 1),\n",
    "            \"Concept\" : torch.cat((data[\"Concept\"].x, node_dict_emb[\"Concept\"]), dim = 1),\n",
    "            \"Class\" : torch.cat((data[\"Class\"].x, node_dict_emb[\"Class\"]), dim = 1)\n",
    "        }\n",
    "        pred = self.classifier(\n",
    "            node_dict,\n",
    "            edge_dict\n",
    "        )\n",
    "\n",
    "        return pred\n",
    "    \n",
    "    class Classifier(torch.nn.Module):\n",
    "        def __init__(self, input_channels):\n",
    "            super().__init__()\n",
    "            self.mlp = MLP([input_channels * 2, 512, 256, 128, 64, 1])\n",
    "\n",
    "        def forward(self, node, edge) -> Tensor:\n",
    "            edge_feat_oer_before = torch.squeeze(node[\"OER\"][edge[(\"OER\", \"before_sr\", \"OER\")][0]])\n",
    "            edge_feat_oer_after = torch.squeeze(node[\"OER\"][edge[(\"OER\", \"before_sr\", \"OER\")][1]])\n",
    "            edge_vec = torch.cat((edge_feat_oer_before, edge_feat_oer_after), dim = 1)\n",
    "            prod = self.mlp(edge_vec)\n",
    "            return torch.squeeze(prod)\n",
    "        \n",
    "    class HeteroGNN(torch.nn.Module):\n",
    "        def __init__(self, node_types, heads, hidden_channels, out_channels, num_layers):\n",
    "            super().__init__()\n",
    "\n",
    "\n",
    "            self.lin_dict = torch.nn.ModuleDict()\n",
    "            for node_type in node_types:\n",
    "                self.lin_dict[node_type] = Linear(-1, hidden_channels)\n",
    "\n",
    "            self.convs = torch.nn.ModuleList()\n",
    "            for _ in range(num_layers):\n",
    "                conv = HeteroConv({\n",
    "                    ('OER', 'before_ep', 'OER') : SAGEConv((-1, -1), hidden_channels, heads =heads,  add_self_loops = True, cached = False),\n",
    "                    ('OER', 'covers', 'Concept') : SAGEConv((-1, -1), hidden_channels, heads =heads,  add_self_loops = False, cached = False),\n",
    "                    ('Concept', 'belongs', 'Class') : SAGEConv((-1, -1), hidden_channels, heads =heads,  add_self_loops = False, cached = False),\n",
    "                    ('Concept', 'rev_covers', 'OER') : SAGEConv((-1, -1), hidden_channels, heads =heads,  add_self_loops = False, cached = False),\n",
    "                    ('Class', 'rev_belongs', 'Concept') : SAGEConv((-1, -1), hidden_channels, heads =heads,  add_self_loops = False, cached = False)\n",
    "                }, aggr = 'mean') #experiment with cat for aggr instead of mean\n",
    "                self.convs.append(conv)\n",
    "\n",
    "            self.lin = Linear(hidden_channels, out_channels)\n",
    "\n",
    "        def forward(self, x_dict, edge_index_dict):\n",
    "            x_dict = {\n",
    "                node_type: self.lin_dict[node_type](x)\n",
    "                for node_type, x in x_dict.items()\n",
    "            }\n",
    "            for conv in self.convs:\n",
    "                x_dict = conv(x_dict, edge_index_dict)\n",
    "            return x_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Layers</th>\n",
       "      <th>Channels</th>\n",
       "      <th>Time</th>\n",
       "      <th>Test Precision</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Test F1</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>36.399593</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.914474</td>\n",
       "      <td>0.912509</td>\n",
       "      <td>0.913633</td>\n",
       "      <td>3.25819</td>\n",
       "      <td>36.395284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epochs  Learning rate  Layers  Channels       Time  Test Precision   \n",
       "0     300           0.01       6        16  36.399593        0.865169  \\\n",
       "\n",
       "   Test Accuracy  Test Recall   Test F1     Loss   Duration  \n",
       "0       0.914474     0.912509  0.913633  3.25819  36.395284  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ModelSAGE = pd.DataFrame()\n",
    "v = 'v8'\n",
    "seed_everything()\n",
    "for params in selected_params:\n",
    "    for n in range(1) :\n",
    "        train_data[\"OER\", \"before_sr\", \"OER\"].edge_label = cross_val_data_train[n][\"OER\", \"before_sr\", \"OER\"][\"edge_label\"]\n",
    "        train_data[\"OER\", \"before_sr\", \"OER\"].edge_label_index = cross_val_data_train[n][\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"]\n",
    "        test_data[\"OER\", \"before_sr\", \"OER\"].edge_label = cross_val_data_test[n][\"OER\", \"before_sr\", \"OER\"][\"edge_label\"]\n",
    "        test_data[\"OER\", \"before_sr\", \"OER\"].edge_label_index = cross_val_data_test[n][\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"]\n",
    "        \n",
    "        results = {}\n",
    "\n",
    "        model = ModelSAGE(node_types = data.node_types, heads = 3, hidden_channels = params['hidden_channels'], entity_features = params['entity_features'], out_channels = 1, num_layers = params['num_layers'])\n",
    "        start = time.time()\n",
    "        train_results = train(model, train_data, params['epochs'], params['lr'])\n",
    "        end = time.time()\n",
    "        model = train_results['Model']\n",
    "        results['Epochs'] = params['epochs']\n",
    "        results['Learning rate'] = params['lr']\n",
    "        results['Layers'] = params['num_layers']\n",
    "        results['Channels'] = params['hidden_channels']\n",
    "        results['Time'] = end - start\n",
    "\n",
    "        '''validation_results = predict(model, val_data)\n",
    "        #results['Validation AUC'] = validation_results[\"AUC\"]\n",
    "        results['Validation Precision'] = validation_results[\"Precision\"]\n",
    "        results['Validation Accuracy'] = validation_results[\"Accuracy\"]\n",
    "        results['Validation Recall'] = validation_results[\"Recall\"]\n",
    "        results['Validation F1'] = validation_results[\"F1\"]'''\n",
    "\n",
    "        test_results = predict(model, test_data)\n",
    "        #results['Test AUC'] = test_results[\"AUC\"]\n",
    "        results['Test Precision'] = test_results[\"Precision\"]\n",
    "        results['Test Accuracy'] = test_results[\"Accuracy\"]\n",
    "        results['Test Recall'] = test_results[\"Recall\"]\n",
    "        results['Test F1'] = test_results[\"F1\"]\n",
    "\n",
    "        loss_values = train_results['Loss_values']\n",
    "        results['Loss'] = train_results['Loss']\n",
    "        results['Duration'] = train_results['Duration']\n",
    "        df_ModelSAGE = pd.concat([df_ModelSAGE, pd.DataFrame([results])], ignore_index = True)\n",
    "df_ModelSAGE.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91\n",
      "0.93\n",
      "0.96\n"
     ]
    }
   ],
   "source": [
    "print(round(df_ModelSAGE[\"Test Accuracy\"].values.min(), 2))\n",
    "print(round(df_ModelSAGE[\"Test Accuracy\"].values.mean(), 2))\n",
    "print(round(df_ModelSAGE[\"Test Accuracy\"].values.max(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1]\n",
      "tensor([0, 0, 0, 1, 1])\n",
      "tensor([   3, 1603,  545, 1779, 1460])\n",
      "tensor([1940, 1433,  578, 1780, 1461])\n",
      "tensor([0, 0, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "def predict_labels(model, test_data):\n",
    "\n",
    "    preds = model(test_data).detach().numpy()\n",
    "    preds_labels = (preds > 0.5) * 1\n",
    "    ground_truths = test_data[\"OER\", \"before_sr\", \"OER\"].edge_label\n",
    "    assert preds.shape == ground_truths.shape, f'ERROR : Shapes differ between prediction and ground truth ! ({preds.shape, ground_truths.shape})'\n",
    "    precision = precision_score(ground_truths, preds_labels, zero_division = np.nan)\n",
    "    accuracy = accuracy_score(ground_truths, preds_labels)\n",
    "    f1 = f1_score(ground_truths, preds_labels, average='macro')\n",
    "    recall = recall_score(ground_truths, preds_labels, average='macro')\n",
    "    return {\n",
    "        #'AUC' : auc_score,\n",
    "        'Precision' : precision,\n",
    "        'Accuracy' : accuracy,\n",
    "        'Recall' : recall,\n",
    "        'F1' : f1,\n",
    "        'preds' : preds_labels,\n",
    "        'truths': ground_truths\n",
    "    }\n",
    "results_labels = predict_labels(model, test_data)\n",
    "print(results_labels['preds'][:5])\n",
    "print(results_labels['truths'][:5])\n",
    "print(test_data[\"OER\", \"before_sr\", \"OER\"].edge_label_index[0][:5])\n",
    "print(test_data[\"OER\", \"before_sr\", \"OER\"].edge_label_index[1][:5])\n",
    "print(test_data[\"OER\", \"before_sr\", \"OER\"].edge_label[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400 2400\n",
      "['Evolutionary_psychology' 'Psychology' 'Spock' 'Steven_Pinker'\n",
      " 'William_James']\n"
     ]
    }
   ],
   "source": [
    "def get_concepts(c_id, df_concepts):\n",
    "    return df_concepts[df_concepts['OER'] == c_id]['Concept'].values\n",
    "\n",
    "def remap_oer_id(c_id, unique_oer_id):\n",
    "    return unique_oer_id[unique_oer_id['mappedID'] == c_id]['OER'].values[0]\n",
    "\n",
    "c_id = 2400\n",
    "true_c_id = remap_oer_id(c_id, unique_oer_id)\n",
    "print(c_id, true_c_id)\n",
    "print(get_concepts(true_c_id, df_concepts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_index(a, b):\n",
    "    '''\n",
    "    Calculates the Jaccard index between two sets or lists\n",
    "    Input :\n",
    "        a,b : input sets or lists\n",
    "    Output :\n",
    "        jaccard index\n",
    "    '''\n",
    "    #if(type(a) == list):\n",
    "    a = set(a)\n",
    "    #if(type(b) == list):\n",
    "    b = set(b)\n",
    "    return len(a & b) / len(a | b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(results_labels['truths'])\n",
    "positive_list = []\n",
    "negative_list = []\n",
    "for i in range(size):\n",
    "    oer_one = test_data[\"OER\", \"before_sr\", \"OER\"].edge_label_index[0][i].item()\n",
    "    oer_two = test_data[\"OER\", \"before_sr\", \"OER\"].edge_label_index[1][i].item()\n",
    "    oer_one_concepts = get_concepts(remap_oer_id(oer_one, unique_oer_id), df_concepts)\n",
    "    oer_two_concepts = get_concepts(remap_oer_id(oer_two, unique_oer_id), df_concepts)\n",
    "    jaccard = jaccard_index(oer_one_concepts, oer_two_concepts)\n",
    "    if test_data[\"OER\", \"before_sr\", \"OER\"].edge_label[i] == 0:\n",
    "        negative_list.append(jaccard)\n",
    "    else:\n",
    "        positive_list.append(jaccard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(positive_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(negative_list)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clara-datasets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
