{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000 NaN values in chapters.\n",
      "0000 Nan values in concepts.\n",
      "0000 Nan values in classes.\n",
      "0000 Nan values in episdes precedences.\n",
      "0000 Nan values in series precedences.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "main_publisher = 'OYC'\n",
    "\n",
    "script_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "path = os.path.join(script_dir, '../Data/' + main_publisher + '/')\n",
    "\n",
    "df_chapters = pd.read_csv(path + 'chapters.csv', delimiter = '|')\n",
    "df_chapters_embeddings = pd.read_csv(path + 'embeddings_chapters.csv', delimiter = '|', index_col=0)\n",
    "df_concepts = pd.read_csv(path + 'concepts_bis.csv', delimiter = '|')\n",
    "df_concepts_embeddings = pd.read_csv(path + 'embeddings_concepts_bis.csv', delimiter = '|', index_col=0)\n",
    "df_classes = pd.read_csv(path + 'classes_bis.csv', delimiter = '|')\n",
    "df_classes_embeddings = pd.read_csv(path + 'embeddings_classes_bis.csv', delimiter = '|', index_col=0)\n",
    "df_precedences_episodes = pd.read_csv(path + 'precedences_episodes.csv', delimiter = '|')\n",
    "df_precedences_series = pd.read_csv(path + 'precedences_series.csv', delimiter = '|')\n",
    "\n",
    "df_concepts['Concept'] = df_concepts['Concept'].apply(lambda x : x.split('/')[-1])\n",
    "\n",
    "df_classes = df_classes.dropna()\n",
    "print(f'{df_chapters[\"Cid\"].isna().sum().sum():04d} NaN values in chapters.')\n",
    "print(f'{df_concepts.isna().sum().sum():04d} Nan values in concepts.')\n",
    "print(f'{df_classes.isna().sum().sum():04d} Nan values in classes.')\n",
    "print(f'{df_precedences_episodes.isna().sum().sum():04d} Nan values in episdes precedences.')\n",
    "print(f'{df_precedences_series.isna().sum().sum():04d} Nan values in series precedences.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "unique_oer_id = id_mapper(df_chapters['Cid'], 'OER')\n",
    "unique_concept_id =  id_mapper(df_concepts['Concept'], 'Concept')\n",
    "unique_class_id =  id_mapper(df_classes['Class'], 'Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16786])\n",
      "torch.Size([2, 16786])\n",
      "torch.Size([2, 2097])\n",
      "torch.Size([2, 423])\n",
      "torch.Size([2, 58295])\n",
      "torch.Size([2, 58295])\n"
     ]
    }
   ],
   "source": [
    "oer_covers_concept_subject = edge_construction(df1 = df_concepts, df2 = unique_oer_id, col = 'mappedID', \n",
    "                                       how = 'left', right_on = 'OER')\n",
    "oer_covers_concept_pr = edge_construction(df1 = df_concepts, df2 = unique_oer_id, col = 'PR', \n",
    "                                          how = 'right', right_on = 'OER')\n",
    "oer_covers_concept_object = edge_construction(df1 = df_concepts, df2 = unique_concept_id, col = 'mappedID', \n",
    "                                       how = 'left', right_on = 'Concept')\n",
    "\n",
    "oer_before_oer_ep_subject = edge_construction(df1 = df_precedences_episodes, df2 = unique_oer_id, col = 'mappedID', \n",
    "                                   how = 'left', left_on = 'Before', right_on = 'OER')\n",
    "oer_before_oer_ep_object = edge_construction(df1 = df_precedences_episodes, df2 = unique_oer_id, col = 'mappedID', \n",
    "                                   how = 'left', left_on = 'After', right_on = 'OER')\n",
    "oer_before_oer_sr_subject = edge_construction(df1 = df_precedences_series, df2 = unique_oer_id, col = 'mappedID', \n",
    "                                   how = 'left', left_on = 'Before', right_on = 'OER')\n",
    "oer_before_oer_sr_object = edge_construction(df1 = df_precedences_series, df2 = unique_oer_id, col = 'mappedID', \n",
    "                                   how = 'left', left_on = 'After', right_on = 'OER')\n",
    "\n",
    "concept_belongs_class_subject = edge_construction(df1 = df_classes, df2 = unique_concept_id, col = 'mappedID', \n",
    "                                   how = 'left', left_on = 'Concept', right_on = 'Concept')\n",
    "concept_belongs_class_object = edge_construction(df1 = df_classes, df2 = unique_class_id, col = 'mappedID', \n",
    "                                   how = 'left', left_on = 'Class', right_on = 'Class')\n",
    "\n",
    "oer_covers_concept = torch.stack([oer_covers_concept_subject, oer_covers_concept_object], dim = 0).long()\n",
    "oer_covers_concept_rev = torch.stack([oer_covers_concept_object, oer_covers_concept_subject], dim = 0).long()\n",
    "oer_before_oer_ep = torch.stack([oer_before_oer_ep_subject, oer_before_oer_ep_object], dim = 0).long()\n",
    "oer_before_oer_sr = torch.stack([oer_before_oer_sr_subject, oer_before_oer_sr_object], dim = 0).long()\n",
    "concept_belongs_class = torch.stack([concept_belongs_class_subject, concept_belongs_class_object], dim = 0).long()\n",
    "concept_belongs_class_rev = torch.stack([concept_belongs_class_object, concept_belongs_class_subject], dim = 0).long()\n",
    "print(oer_covers_concept.shape)\n",
    "print(oer_covers_concept_rev.shape)\n",
    "print(oer_before_oer_ep.shape)\n",
    "print(oer_before_oer_sr.shape)\n",
    "print(concept_belongs_class.shape)\n",
    "print(concept_belongs_class_rev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters_embeddings_tmp = {}\n",
    "concepts_embeddings_tmp = {} \n",
    "classes_embeddings_tmp = {}\n",
    "\n",
    "chapters_r = range(len(df_chapters['Cid'].unique()))\n",
    "concepts_c = range(len(df_concepts['Concept'].unique()))\n",
    "classes_c = range(len(df_classes['Class'].unique()))\n",
    "\n",
    "chapters_embeddings = np.zeros(shape=(len(chapters_r), 768))\n",
    "concepts_embeddings = np.zeros(shape=(len(concepts_c), 768))\n",
    "classes_embeddings = np.zeros(shape=(len(classes_c), 768))\n",
    "\n",
    "\n",
    "i = 0\n",
    "for r in chapters_r:\n",
    "    chapters_embeddings_tmp[r] = list(filter(None, df_chapters_embeddings['BERT'][r].strip(\"[]\\n\").replace(\"'\",\"\").split(\" \")))\n",
    "    chapters_embeddings_tmp[r] = [float(f) for f in chapters_embeddings_tmp[r]]\n",
    "    for a in range(len(chapters_embeddings_tmp[r])):\n",
    "            chapters_embeddings[i][a] = chapters_embeddings_tmp[r][a]\n",
    "    i += 1\n",
    "\n",
    "i = 0\n",
    "for r in concepts_c:\n",
    "    concepts_embeddings_tmp[r] = list(filter(None, df_concepts_embeddings['BERT'][r].strip(\"[]\\n\").replace(\"'\",\"\").split(\" \")))\n",
    "    concepts_embeddings_tmp[r] = [float(f) for f in concepts_embeddings_tmp[r]]\n",
    "    for a in range(len(concepts_embeddings_tmp[r])):\n",
    "            concepts_embeddings[i][a] = concepts_embeddings_tmp[r][a]\n",
    "    i += 1   \n",
    "\n",
    "i = 0\n",
    "for r in classes_c:\n",
    "    classes_embeddings_tmp[r] = list(filter(None, df_classes_embeddings['BERT'][r].strip(\"[]\\n\").replace(\"'\",\"\").split(\" \")))\n",
    "    classes_embeddings_tmp[r] = [float(f) for f in classes_embeddings_tmp[r]]\n",
    "    for a in range(len(classes_embeddings_tmp[r])):\n",
    "            classes_embeddings[i][a] = classes_embeddings_tmp[r][a]\n",
    "    i += 1\n",
    "\n",
    "chapters_embeddings = torch.from_numpy(chapters_embeddings).to(torch.float32)\n",
    "concepts_embeddings = torch.from_numpy(concepts_embeddings).to(torch.float32)\n",
    "classes_embeddings = torch.from_numpy(classes_embeddings).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2097])\n",
      "HeteroData(\n",
      "  \u001b[1mOER\u001b[0m={\n",
      "    node_id=[2550],\n",
      "    x=[2550, 768]\n",
      "  },\n",
      "  \u001b[1mConcept\u001b[0m={\n",
      "    node_id=[6007],\n",
      "    x=[6007, 768]\n",
      "  },\n",
      "  \u001b[1mClass\u001b[0m={\n",
      "    node_id=[292],\n",
      "    x=[292, 768]\n",
      "  },\n",
      "  \u001b[1m(OER, covers, Concept)\u001b[0m={\n",
      "    edge_index=[2, 16786],\n",
      "    edge_attr=[16830]\n",
      "  },\n",
      "  \u001b[1m(Concept, rev_covers, OER)\u001b[0m={ edge_index=[2, 16786] },\n",
      "  \u001b[1m(OER, before_sr, OER)\u001b[0m={ edge_index=[2, 423] },\n",
      "  \u001b[1m(OER, before_ep, OER)\u001b[0m={ edge_index=[2, 2097] },\n",
      "  \u001b[1m(Concept, belongs, Class)\u001b[0m={ edge_index=[2, 58295] },\n",
      "  \u001b[1m(Class, rev_belongs, Concept)\u001b[0m={ edge_index=[2, 58295] }\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abazouzi/Documents/Code/PrerequisiteLearning/clara-datasets/lib64/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "data = HeteroData()\n",
    "data['OER'].node_id = torch.tensor(unique_oer_id['mappedID'].values)\n",
    "data['OER'].x = chapters_embeddings\n",
    "data['Concept'].node_id = torch.tensor(unique_concept_id['mappedID'].values)\n",
    "data['Concept'].x = concepts_embeddings\n",
    "data['Class'].node_id = torch.tensor(unique_class_id['mappedID'].values)\n",
    "data['Class'].x = classes_embeddings\n",
    "data['OER', 'covers', 'Concept'].edge_index = oer_covers_concept\n",
    "data['Concept', 'rev_covers', 'OER'].edge_index = oer_covers_concept_rev\n",
    "\n",
    "data['OER', 'covers', 'Concept'].edge_attr = oer_covers_concept_pr\n",
    "print(oer_before_oer_ep.shape)\n",
    "data['OER', 'before_sr', 'OER'].edge_index = oer_before_oer_sr\n",
    "data['OER', 'before_ep', 'OER'].edge_index = oer_before_oer_ep\n",
    "data['Concept', 'belongs', 'Class'].edge_index = concept_belongs_class\n",
    "data['Class', 'rev_belongs', 'Concept'].edge_index = concept_belongs_class_rev\n",
    "\n",
    "#data = T.ToUndirected()(data)\n",
    "data.validate()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def seed_everything(seed=0):                                                  \n",
    "       random.seed(seed)                                                            \n",
    "       torch.manual_seed(seed)                                                      \n",
    "       torch.cuda.manual_seed_all(seed)                                             \n",
    "       np.random.seed(seed)                                                         \n",
    "       os.environ['PYTHONHASHSEED'] = str(seed)                                     \n",
    "       torch.backends.cudnn.deterministic = True                                    \n",
    "       torch.backends.cudnn.benchmark = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610\t Edges for training\n",
      "75\t Edges for validation\n",
      "75\t Edges for testing\n",
      "tensor([1692, 1554, 2541, 1480,  422])\n",
      "tensor([2187,  412, 1881, 1991,  541])\n",
      "tensor([2529,  769, 2363, 1027, 1958])\n",
      "tensor([1693, 1555, 2542, 1481,  423])\n",
      "tensor([2188,  413, 1882, 1992,  542])\n",
      "tensor([2530,  770, 2364, 1028, 1959])\n"
     ]
    }
   ],
   "source": [
    "agnostic = False\n",
    "if agnostic:\n",
    "    num_val = 0.5\n",
    "    num_test = 0.5\n",
    "else:\n",
    "    num_val = 0.1\n",
    "    num_test = 0.1\n",
    "seed_everything()\n",
    "transform = T.RandomLinkSplit(\n",
    "    num_val = num_val,\n",
    "    num_test = num_test,\n",
    "    disjoint_train_ratio = 0.0,\n",
    "    neg_sampling_ratio = 0.8,\n",
    "    add_negative_train_samples = True,\n",
    "    edge_types=('OER', 'before_sr', 'OER')\n",
    ")\n",
    "\n",
    "train_data, val_data, test_data = transform(data)\n",
    "print(f'{len(train_data[\"OER\", \"before_sr\", \"OER\"].edge_label.detach().numpy())}\\t Edges for training')\n",
    "print(f'{len(val_data[\"OER\", \"before_sr\", \"OER\"].edge_label.detach().numpy())}\\t Edges for validation')\n",
    "print(f'{len(test_data[\"OER\", \"before_sr\", \"OER\"].edge_label.detach().numpy())}\\t Edges for testing')\n",
    "print(train_data[\"OER\", \"before_sr\", \"OER\"].edge_label_index[0][:5])\n",
    "print(val_data[\"OER\", \"before_sr\", \"OER\"].edge_label_index[0][:5])\n",
    "print(test_data[\"OER\", \"before_sr\", \"OER\"].edge_label_index[0][:5])\n",
    "print(train_data[\"OER\", \"before_sr\", \"OER\"].edge_label_index[1][:5])\n",
    "print(val_data[\"OER\", \"before_sr\", \"OER\"].edge_label_index[1][:5])\n",
    "print(test_data[\"OER\", \"before_sr\", \"OER\"].edge_label_index[1][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760\n",
      "760\n",
      "760\n",
      "1059\n"
     ]
    }
   ],
   "source": [
    "seed_everything()\n",
    "cross_val_data = {}\n",
    "cross_val_data[\"OER\", \"before_sr\", \"OER\"] = {}\n",
    "print(len(train_data[\"OER\", \"before_sr\", \"OER\"].edge_label_index[0]) + \n",
    "      len(val_data[\"OER\", \"before_sr\", \"OER\"].edge_label_index[0]) +\n",
    "      len(test_data[\"OER\", \"before_sr\", \"OER\"].edge_label_index[0]))\n",
    "\n",
    "cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label\"] = torch.cat(\n",
    "    [train_data[\"OER\", \"before_sr\", \"OER\"].edge_label, \n",
    "     val_data[\"OER\", \"before_sr\", \"OER\"].edge_label,\n",
    "     test_data[\"OER\", \"before_sr\", \"OER\"].edge_label], \n",
    "    dim = 0).long()\n",
    "cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"] = torch.cat(\n",
    "    [train_data[\"OER\", \"before_sr\", \"OER\"].edge_label_index, \n",
    "     val_data[\"OER\", \"before_sr\", \"OER\"].edge_label_index,\n",
    "     test_data[\"OER\", \"before_sr\", \"OER\"].edge_label_index], \n",
    "    dim = 1).long()\n",
    "cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_index\"] = torch.cat(\n",
    "    [train_data[\"OER\", \"before_sr\", \"OER\"].edge_index, \n",
    "     val_data[\"OER\", \"before_sr\", \"OER\"].edge_index,\n",
    "     test_data[\"OER\", \"before_sr\", \"OER\"].edge_index],\n",
    "    dim = 1).long()\n",
    "print(len(cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label\"]))\n",
    "print(len(cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][0]))\n",
    "print(len(cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_index\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   3, 1603,  545, 1779, 1460, 1287,  331, 1212,  402,  587, 1371, 1932,\n",
      "        1559, 1114,  876, 2440,   48, 2233, 1376, 1706, 1384,  795, 1875, 1043,\n",
      "         519,  824, 1455, 2348, 1907, 1973,  749, 1662, 1791, 1159, 1280, 1996,\n",
      "        1221,  782, 1430,  515, 1985,   53, 2321, 1096, 2333, 2301, 2225,  264,\n",
      "        1864, 1287, 1554, 1070,  374, 1018, 1682, 1024, 2303, 1333, 2010, 2275,\n",
      "        1894, 1072,  443, 1044, 2083, 1814,  264,  957,  591,  916,  933,  734,\n",
      "         541, 1119, 1176,  200, 1040,  306,  853, 2194, 2232, 1671, 2073, 2329,\n",
      "         525, 1914,  907,  960, 1322, 1303, 1759, 1284,  185, 1363, 2141, 2343,\n",
      "         634, 1482,  129,  787, 2260, 1225, 1933, 1353,  743, 2541, 2403, 1935,\n",
      "         301,  852, 2250, 1768,  518, 2179,  985, 2004, 2325, 2161, 1246, 1067,\n",
      "        1027, 2336,  434,  407,  662,  169, 2092, 1686, 1502, 2360, 2546,  656,\n",
      "         730, 1527,  502,  627,  799, 2212, 2523,  678, 1050,   21, 1040, 1367,\n",
      "         428, 2417,  204, 1323,  148, 1094, 1152,  924, 2376, 1109, 1448, 1982,\n",
      "        2012, 2325, 2256,  164,  692, 2016,  504,  411, 1536, 1981,  811,  475,\n",
      "        1348,  210,  385,  458,  968, 1126, 1379, 2529, 1084, 2356,  607, 1494,\n",
      "         530, 1844,  535, 1734, 1514, 2216,  481, 1253, 1312,  381,   51, 1506,\n",
      "         754, 1373,  905,  639,  334,  870,  385,  426, 1266, 2164, 2110, 1899,\n",
      "          40,   48,   16, 1237, 1574,  309, 1966, 1105,  520,  955, 1464, 2013,\n",
      "        2198, 2310, 1218, 2206,  825,  824, 1394, 2227, 1818,   74,  207, 1985,\n",
      "        2042, 2167, 1170, 1060, 1801, 1585, 2369, 2456,  694, 2043, 1065,  924,\n",
      "        2016,  856, 2176, 2172, 2190, 1577, 1507,  597, 1599, 1267,  672, 2394,\n",
      "         497, 2078,   47,  583, 1881,  201, 1054, 1987, 2320, 1970, 1740, 2234,\n",
      "         887, 2103, 2073, 1362, 2217, 1941,  561, 2468, 2089, 2198,  657, 2146,\n",
      "         857,  708,  346, 2213,   85, 2407, 2016,  668, 1657, 1547,  364, 1851,\n",
      "         406, 1569, 2494,  350, 2087,  553, 1267,   92, 1791,    5, 1621,  283,\n",
      "        1692, 2264,   57,  312, 2007, 2062,  569, 1995, 1232, 1752, 2333, 1324,\n",
      "        2488, 2301, 1399, 2313, 2128,  626, 1104,  301,  800,  271, 1787, 2043,\n",
      "         992, 1095,  608,  790,  621, 1480,  141,   67, 1778, 2000,  856, 1541,\n",
      "        1615,  725, 1624, 1553, 1728, 1299, 1668, 1276,  469, 1962, 1847, 1278,\n",
      "         736,  557, 2322, 1537,  927, 2541, 1200,   71,  459,  941, 1795, 1435,\n",
      "         849, 1274, 1869, 2498,  785, 1830,  369, 2525,  673, 1474, 2389, 2114,\n",
      "         330, 2432, 2517,  825,  410,  640, 1929, 2290, 1032,  891,  483, 1875,\n",
      "           0, 1869,  373,  486,  242,  492, 1466,  191, 1037, 1758,  776, 1454,\n",
      "        1992, 1289, 1726,  230,  669, 2097,  276, 2407,  133, 1699, 2306, 1964,\n",
      "        1867,  177,  689,   80, 2509, 1203,  864, 2368,  832,  463, 1805,  300,\n",
      "         204,  108,  855,   39,  563, 1021,  325, 1568,  946, 1094,  332, 2182,\n",
      "         240,  259, 2024,  526, 1872, 1844,  422, 2220, 2239, 2486, 1742, 2487,\n",
      "        1987,  318,  632,  292, 2273,  227, 2401, 2475,  769, 2020,  355, 1820,\n",
      "        1402, 1409, 1892,  385,  901, 2363, 2129,   87,  614, 1942, 1184, 2337,\n",
      "        1858, 1435, 2363, 1456, 1164, 1978,   46, 2283,  295,  575, 2508,  409,\n",
      "        1942,  103,  806, 1074, 1383, 2308,  381, 2056, 2424, 1657,   73,  236,\n",
      "         127,  134, 1962, 1715, 2296, 1151,  683,  593, 1962,  532, 1053, 1919,\n",
      "        2304, 1719, 1139, 1867, 1888, 2382, 1343,  358, 1806, 1103, 1958,  128,\n",
      "        2442,  390,  668, 2109, 2135, 2242,  468,  193, 2315, 1713,  126, 1908,\n",
      "        1640, 1552, 1991, 2287, 1486, 1610,  855, 1465,  718, 2161, 1736, 1164,\n",
      "        1609, 1287,  729, 2268, 2035,  447,  838, 1146, 1404,  418, 1090, 2031,\n",
      "        1786, 1521,  331,  430,  481, 2309,  775, 2027,  976, 1717, 2463, 2085,\n",
      "        1247, 2294, 1041, 2039, 1182,  628, 2321, 2141, 1567, 2035, 1812, 1428,\n",
      "        1294, 2175, 1922, 1674, 2493, 1534, 1314,  992,  699, 1123, 2068,  243,\n",
      "        1956, 2494,   99, 1026,  650,  260, 1177,  726, 1069,  451,   43,  908,\n",
      "         618,  393,  644, 1400,  301, 1602, 1001, 2429,  150, 2235,  274,  895,\n",
      "        1099,   76, 1086, 2151,  119,  379,  702, 2534,  723, 1242, 2008,  359,\n",
      "        2156, 1175, 2298, 1802, 1627,  603, 1895,   10,  623, 1660, 1805, 1954,\n",
      "        1471, 2135, 1277, 1441,   61, 1338,  819,  762,   28,  442, 1157, 1600,\n",
      "        2337, 1884,  267, 1366,  150,  153,  458, 1568,  614, 1745, 1178, 1100,\n",
      "         605, 1673,  492,  511,  796, 2298, 2187, 1779,  557, 1994,   11, 2083,\n",
      "        2448, 2107,  394, 1468, 1259, 1474,  108, 2435,  998, 1414,  788, 2501,\n",
      "         802,  113, 2087, 1837, 1375, 2051, 1363,  412, 1380, 1078,  717, 2295,\n",
      "         220, 2244,  213, 1357, 2319, 1023,  620, 1774,  438, 2249,  202, 1680,\n",
      "        1547,  265,   24, 1388,  881, 2252, 2119, 2393, 1348, 1980, 1292,  159,\n",
      "        2399,  435, 2355,  230, 2271, 1634,  547, 1224,  506, 1332, 2411,   43,\n",
      "        1218,  719, 1134, 1195,  951,  947, 1020, 2057, 1207, 2405,    5, 1179,\n",
      "          34,  249, 2236,  429,  990, 1902, 2387,  398, 2504, 1426, 1800, 2279,\n",
      "        1310, 2240, 2097, 1842])\n",
      "tensor([1940, 1433,  578, 1780, 1461, 1867,  238, 1213,  403,  588, 1372,   71,\n",
      "        1560, 1115,  877, 1216, 1207, 1632,  914, 1707,  194,  796,  189,  974,\n",
      "         520, 1024, 1605, 2349, 1891, 1974,  750, 1663,  118,  391, 1281, 1997,\n",
      "        1222,  783, 1431,  516, 1986,  875,  116,  836,  756, 1095,  866, 1893,\n",
      "        1865, 1700, 1555,  581,  375, 1019, 1465, 2423, 2304, 1334, 1001, 2276,\n",
      "        1104, 1688, 1893, 1045, 1166,  478,  235, 2453,  592,  917,  934,  514,\n",
      "         542, 1120,  192, 2262, 1491, 2428,  256, 2195, 2429, 1535, 2074, 2330,\n",
      "         526, 1915,  243,  961,  905, 1304, 1760, 1285,  186, 2104, 2173, 2344,\n",
      "         635, 1980, 1512, 2304, 2261, 1226, 2073, 1354,  744, 2542,  773, 1936,\n",
      "        1417,  203, 2424, 1769, 2389,  630,  986, 2005,  641,   69,  276,  850,\n",
      "        1028, 2337,  435, 1865,  663,  170, 2093, 1687, 1503, 1711, 2547,  173,\n",
      "         731, 1528,  503,  628, 2080, 2213, 2524,  679, 1051,   22, 1327, 1368,\n",
      "        1430, 2418, 2444, 2134, 2199,  909, 2031,  925, 2377, 1110, 1449, 1983,\n",
      "        2013, 2326, 2257,  195, 2536, 1613, 2224,  412, 1311, 1803,  812,  476,\n",
      "        1349,  628, 1888,  871,  969, 1352, 1380, 2530, 1085, 2357,  608, 1495,\n",
      "         531, 1845,  536, 1735, 1515,  333,  482, 1254, 1286, 2297,   52, 1507,\n",
      "         755, 2342, 1791,  640,   79,  871,  386,  427, 1751,  448,  358, 1900,\n",
      "        2364,   49,   17, 1238, 1575,  310, 1967, 1228, 1671, 1166, 1102, 1827,\n",
      "        2199, 2311, 1219, 2207,  826, 2542, 1395, 2228,  822, 2489,  708,  122,\n",
      "         911, 2168, 1171, 1061, 1518, 1694, 2370, 2457,  695, 2364, 1066,  943,\n",
      "        2017,  857, 2177, 2111, 1196,  330,  255,  598,  405, 1268, 2356, 2395,\n",
      "         498, 2079,   82,  584, 1882,   68, 1055, 1666, 1733, 1971, 1741, 2235,\n",
      "         888, 2104, 1982, 1363,  903,    1,  115, 2469, 1904, 2173,  658, 2147,\n",
      "         674,  547,  347, 1581,   86, 1648, 1529,  669, 1116, 1548,  365, 1852,\n",
      "         407, 2068,  976,  351,  345,  554, 2089,   93,  823,    6,  763,  284,\n",
      "        1693, 2265,   58,  210, 2346, 2063,  570, 1080, 1233, 1619, 2334, 1325,\n",
      "        2489, 1098, 1400, 2314, 2535, 1340, 1105,  576,  801,  215, 1788, 2044,\n",
      "         993,  158, 1866,  649,  622, 1481,  142,   68,  105, 2001,  211, 1542,\n",
      "        1616, 1333,  855, 2024, 1729, 1300, 1669, 2401,  470,  878, 1402, 2546,\n",
      "         737, 1444, 2323,  767, 1305,  554, 1201,  522, 2282,  942, 1796, 1436,\n",
      "         850, 1275, 1919, 2499,  690, 1831,  370,  759,  674,  615, 2390, 2115,\n",
      "         331,  148, 2518, 2051, 1899,  988, 1930, 2291, 1033, 2473, 1635, 1876,\n",
      "         581, 1870,  374,  487, 1739,  493, 1467,  107, 1038,   35,  777, 1455,\n",
      "        1729, 1290,  871,  969, 1086, 2098,  277,  733,  591, 1700, 2307,   13,\n",
      "        1320,  178,  690,   81, 2510, 1204,  865, 1288,  833,  464,  727,  475,\n",
      "        1713,  109,  972,   40,  564,  435,   61, 1153, 1691, 1095,  320, 2183,\n",
      "         241,  260, 2025, 2073, 2336, 2300,  423, 2221, 1984,  651, 1193,  782,\n",
      "        1988,  319, 2242,  293, 1164,  907, 2123, 2476,  770, 2021,  356, 1821,\n",
      "         949, 1410, 1893, 1229,  902, 2364, 2130, 2186, 1315, 1943, 1185, 1024,\n",
      "        1859,  193,  684, 2238,  780, 1979,  537, 2284, 1547,  818,  625, 1369,\n",
      "        1450, 2076,  807, 1075, 1384, 1652,  382, 2057, 2425, 1658,   74, 2179,\n",
      "         426,  135, 1963, 1897,  203, 1152,  684, 1060, 2541, 2502,  715, 2233,\n",
      "        1021, 1720, 1140, 1642, 1425, 2383, 1344, 2302, 1807,  905, 1959,  131,\n",
      "        2443,  391, 1849, 2110, 1533,  138, 2398,  194, 1646, 1714,  127, 1909,\n",
      "        1641,  232, 1992, 2288, 1487,  545, 2115, 1600, 2249, 2162,  540, 1165,\n",
      "        1610, 1139, 1567, 2269,   40,  448,  839, 1147, 1405,  419, 1091, 2032,\n",
      "        2416, 1522, 1024,  431, 1675, 1732,   56, 2028,  977,  459,  567, 1597,\n",
      "        1248, 2295, 1042, 2040,  280, 2015,  534, 2142, 1568, 2036, 1813, 2126,\n",
      "        1295, 2176, 1923, 1675,  585, 1535, 1315,  110,  700, 1124, 2069, 1324,\n",
      "        1828, 2495,  100, 2461,  651,  580, 1178, 1877, 1070,  452, 1155,  909,\n",
      "        1788, 2322,  645, 1750,  302, 1603, 1002, 2430,  980, 1762, 1747,  896,\n",
      "        1100,   77, 1682, 2152, 1948, 1553, 1777, 2535,  724, 1243, 2009,  360,\n",
      "        2157,  930, 2299, 1803, 1638,  604, 1088,   11,  703, 2281, 1879, 1955,\n",
      "        1472, 2136, 1278, 1442,   62, 1339,  820,  763,   29,  443, 1158, 2190,\n",
      "        1834, 1885,  268,  491,  151, 2420,  459,  599,  615, 1746,  813, 1265,\n",
      "         257, 1971,  411,  512, 1939, 2535, 2188,  209,  558, 1995,  422, 2084,\n",
      "        2449, 1517,  395, 2447, 1260, 2006, 1301, 2436,  469, 1415,  789, 2502,\n",
      "        1775,  114, 2088, 1838, 1376, 2052, 2006,  413,  757, 1079,  718, 2531,\n",
      "         221, 2245,  214, 1358, 2320, 1024, 1046, 1775,  439,  899,  203, 1681,\n",
      "        1156, 1670,   25, 1389,  882, 2253, 2120,   63, 2484, 2101, 1293,  160,\n",
      "        2400, 1370,  155,  231, 2272, 1635,  548, 1091,  507, 1566, 2412,   44,\n",
      "         276, 2475, 1135, 1196,  952,  992, 1727, 1816, 1208, 2406,   42, 2509,\n",
      "          35,  250,  280, 1375, 1978, 1903, 1928,  399, 2505, 1427, 2299, 2280,\n",
      "        1311, 2241, 1640,  799])\n",
      "tensor([0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
      "        1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
      "        1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
      "        0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
      "        1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0,\n",
      "        1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1,\n",
      "        1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n",
      "        1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1,\n",
      "        1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "        1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
      "        1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
      "        0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
      "        0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
      "        1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0,\n",
      "        1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
      "        0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
      "        1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
      "        1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
      "        1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
      "        1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "seed_everything()\n",
    "num_samples = len(cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label\"])\n",
    "shuffled_index = np.arange(num_samples)\n",
    "np.random.shuffle(shuffled_index)\n",
    "cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][0] = cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][0][shuffled_index]\n",
    "cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][1] = cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][1][shuffled_index]\n",
    "cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label\"] = cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label\"][shuffled_index]\n",
    "print(cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][0])\n",
    "print(cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][1])\n",
    "print(cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n",
      "152\n",
      "152\n",
      "------------------------------\n",
      "152\n",
      "152\n",
      "152\n",
      "------------------------------\n",
      "152\n",
      "152\n",
      "152\n",
      "------------------------------\n",
      "152\n",
      "152\n",
      "152\n",
      "------------------------------\n",
      "152\n",
      "152\n",
      "152\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "cv = 5\n",
    "chunk_size = int(len(cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label\"]) / cv)\n",
    "cross_val_chunks = []\n",
    "for n in range(cv):\n",
    "    cross_val_chunk = {}\n",
    "    cross_val_chunk[\"OER\", \"before_sr\", \"OER\"] = {}\n",
    "    cross_val_chunk[\"OER\", \"before_sr\", \"OER\"][\"edge_label\"] = {}\n",
    "    begin = n * chunk_size\n",
    "    if n == cv - 1:\n",
    "        end = len(cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label\"])\n",
    "    else :\n",
    "        end = (n+1) * chunk_size\n",
    "    cross_val_chunk[\"OER\", \"before_sr\", \"OER\"][\"edge_label\"] = cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label\"][begin : end]\n",
    "    cross_val_chunk[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"] = []\n",
    "    cross_val_chunk[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"].append(cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][0][begin : end])\n",
    "    cross_val_chunk[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"].append(cross_val_data[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][1][begin : end])\n",
    "    cross_val_chunks.append(cross_val_chunk)\n",
    "for n in range(cv):\n",
    "    print(len(cross_val_chunks[n][\"OER\", \"before_sr\", \"OER\"][\"edge_label\"]))\n",
    "    print(len(cross_val_chunks[n][\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][0]))\n",
    "    print(len(cross_val_chunks[n][\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][1]))\n",
    "    print(\"------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_data_train = []\n",
    "cross_val_data_test = []\n",
    "for n in range(cv) :\n",
    "    cross_val_data_train_chunk = {}\n",
    "    cross_val_data_train_chunk[\"OER\", \"before_sr\", \"OER\"] = {}\n",
    "    cross_val_data_train_chunk[\"OER\", \"before_sr\", \"OER\"][\"edge_label\"] = torch.cat(\n",
    "    [cross_val_chunks[(n+1)%cv][\"OER\", \"before_sr\", \"OER\"][\"edge_label\"], \n",
    "     cross_val_chunks[(n+2)%cv][\"OER\", \"before_sr\", \"OER\"][\"edge_label\"],\n",
    "     cross_val_chunks[(n+3)%cv][\"OER\", \"before_sr\", \"OER\"][\"edge_label\"],\n",
    "     cross_val_chunks[(n+4)%cv][\"OER\", \"before_sr\", \"OER\"][\"edge_label\"]\n",
    "     ], \n",
    "    dim = 0).long()\n",
    "    cross_val_data_test_chunk = {}\n",
    "    cross_val_data_test_chunk[\"OER\", \"before_sr\", \"OER\"] = {}\n",
    "    cross_val_data_test_chunk[\"OER\", \"before_sr\", \"OER\"][\"edge_label\"] = cross_val_chunks[n][\"OER\", \"before_sr\", \"OER\"][\"edge_label\"]\n",
    "\n",
    "    cross_val_data_train_chunk[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"] = []\n",
    "    cross_val_data_train_chunk[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"].append(torch.cat(\n",
    "    [cross_val_chunks[(n+1)%cv][\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][0], \n",
    "     cross_val_chunks[(n+2)%cv][\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][0],\n",
    "     cross_val_chunks[(n+3)%cv][\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][0],\n",
    "     cross_val_chunks[(n+4)%cv][\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][0]\n",
    "     ], \n",
    "    dim = 0).long())\n",
    "    cross_val_data_train_chunk[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"].append(torch.cat(\n",
    "    [cross_val_chunks[(n+1)%cv][\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][1], \n",
    "     cross_val_chunks[(n+2)%cv][\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][1],\n",
    "     cross_val_chunks[(n+3)%cv][\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][1],\n",
    "     cross_val_chunks[(n+4)%cv][\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][1]\n",
    "     ], \n",
    "    dim = 0).long())\n",
    "    cross_val_data_test_chunk[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"] = []\n",
    "    cross_val_data_test_chunk[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"].append(\n",
    "        cross_val_chunks[n][\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][0])\n",
    "    cross_val_data_test_chunk[\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"].append(\n",
    "        cross_val_chunks[n][\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"][1])\n",
    "    \n",
    "    cross_val_data_train.append(cross_val_data_train_chunk)\n",
    "    cross_val_data_test.append(cross_val_data_test_chunk)\n",
    "\n",
    "len(cross_val_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(608, 1536) torch.Size([608])\n",
      "(152, 1536) torch.Size([152])\n"
     ]
    }
   ],
   "source": [
    "X_train_index = []\n",
    "X_train = []\n",
    "X_test_index = []\n",
    "X_test = []\n",
    "Y_train = []\n",
    "Y_test = []\n",
    "for n in range(cv):\n",
    "    X_train_index.append(cross_val_data_train[n][\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"])\n",
    "    X_train.append(np.concatenate([chapters_embeddings[X_train_index[n][0]],chapters_embeddings[X_train_index[n][1]]], axis=1))\n",
    "    Y_train.append(cross_val_data_train[n][\"OER\", \"before_sr\", \"OER\"][\"edge_label\"])\n",
    "    X_test_index.append(cross_val_data_test[n][\"OER\", \"before_sr\", \"OER\"][\"edge_label_index\"])\n",
    "    X_test.append(np.concatenate([chapters_embeddings[X_test_index[n][0]],chapters_embeddings[X_test_index[n][1]]], axis=1))\n",
    "    Y_test.append(cross_val_data_test[n][\"OER\", \"before_sr\", \"OER\"][\"edge_label\"])\n",
    "\n",
    "print(X_train[0].shape, Y_train[0].shape)\n",
    "print(X_test[0].shape, Y_test[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression :\n",
      "SVM :\n",
      "RBF :\n",
      "Random Forest :\n",
      "Linear Regression :\n",
      "SVM :\n",
      "RBF :\n",
      "Random Forest :\n",
      "Linear Regression :\n",
      "SVM :\n",
      "RBF :\n",
      "Random Forest :\n",
      "Linear Regression :\n",
      "SVM :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abazouzi/Documents/Code/PrerequisiteLearning/clara-datasets/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF :\n",
      "Random Forest :\n",
      "Linear Regression :\n",
      "SVM :\n",
      "RBF :\n",
      "Random Forest :\n"
     ]
    }
   ],
   "source": [
    "from classification import classify_cv_predefined\n",
    "\n",
    "df_bert = classify_cv_predefined(X_train, Y_train, X_test, Y_test, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RBF</td>\n",
       "      <td>0.881579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RBF</td>\n",
       "      <td>0.855263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RBF</td>\n",
       "      <td>0.796053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RBF</td>\n",
       "      <td>0.796053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.776316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.776316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.763158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.756579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.743421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RBF</td>\n",
       "      <td>0.736842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Accuracy\n",
       "18                RBF  0.881579\n",
       "10                RBF  0.855263\n",
       "2                 RBF  0.796053\n",
       "14                RBF  0.796053\n",
       "8   Linear Regression  0.776316\n",
       "12  Linear Regression  0.776316\n",
       "19                 RF  0.763158\n",
       "16  Linear Regression  0.756579\n",
       "3                  RF  0.743421\n",
       "6                 RBF  0.736842"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bert.sort_values(by = ['Accuracy'], ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74\n",
      "0.81\n",
      "0.88\n"
     ]
    }
   ],
   "source": [
    "df_bert_best = df_bert[(df_bert['Model'] == \"RBF\")]\n",
    "print(round(df_bert_best[\"Accuracy\"].values.min(), 2))\n",
    "print(round(df_bert_best[\"Accuracy\"].values.mean(), 2))\n",
    "print(round(df_bert_best[\"Accuracy\"].values.max(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = 'v8'\n",
    "if agnostic :\n",
    "    v = 'Agnostic/' + v\n",
    "else :\n",
    "    v = 'Informed/' + v\n",
    "#df_results.to_csv(f'../Output/Evaluation/{main_publisher}/{v}_.csv', index = False, sep = '|')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clara-datasets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
